{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words Model\n",
    "- Assume the text to be bag of words, i.e the words only matter, but word order or sentence structure does not\n",
    "# Tokenization\n",
    "- break a string of text into smaller chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create WOrd dictionary Plot\n",
    "- favorite novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "- shorten words to their root stems\n",
    "- remove stop words, punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word freqency\n",
    "-downweight most common words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1 (10 PTS)\n",
    "\n",
    "Classification on a pair of categories of your choice\n",
    "\n",
    "1. Choose a pair of categories in the wikipedia folder, and follow the walkthrough code provided to perform binary classification using decision trees. \n",
    "\n",
    "Calculate the appropriate metrics on the  model.\n",
    "Comment, based on the results of your metrics, if your classifier is a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# prepare vectorizer\n",
    "# train decision tree on the vectorizer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The number of max features is set to 100 in the count vectorizer.  Now you will perform another classification task where we vary the number of max features. But first we will set the max depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change max_features in count_vectorizer\n",
    "# set max_depth in decision tree classifier\n",
    "# retrain model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score, f1_score from sklearn.metrics module to evaluate model\n",
    "\n",
    "# To make our lives easier, we’ll use the metrics api from scikit learn to calculate accuracy and f1_score which is the geometric mean of the precision and recall.\n",
    "# First add the import statement to top of your code.\n",
    "\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "# Now suppose we have a predicted column like so:\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# We can calculate accuracy between predicted and actual like so:\n",
    "sm.accuracy_score(y_pred,y_test) \n",
    "\n",
    "# Likewise for the f1 score.  This function requires a “pos_label” to be one of your labels in your data. In my case, I chose, “organ\n",
    "sm.f1_score(y_pred, y_train,pos_label='organ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-evaluate model for various values of max_features and max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-evaluate model for max_features = 1,5,10,50,100,500. \n",
    "# re-evaluate model for max_depth= 3,10,20,100,etc\n",
    "# Do you notice a pattern?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 (10 PTS)\n",
    "\n",
    "All right now, it would be nice if we can plot the variation of  max_features with accuracy.  In which case, we need a function so we don’t keep changing things by hand. I will do one for you that returns the accuracy metric on the test set data, given a max features for the count vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy( num_features):\n",
    "\n",
    "    count_vect = CountVectorizer(max_features=num_features, decode_error='ignore', stop_words = \"english\")\n",
    "\n",
    "    tfidf = TfidfTransformer()\n",
    "    tdmatrix = count_vect.fit_transform(combined)\n",
    "\n",
    "    X = tfidf.fit_transform(tdmatrix)\n",
    "    y= labels\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_depth = 3)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return  sm.accuracy_score(y_pred ,y_test)\n",
    "\n",
    "# try accuracy(30) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, modify the above function so that it does two things:\n",
    "- It returns the f1 score instead of the accuracy score and it allows you to modify the decision tree depth from the function argument. \n",
    "- Call this new function f1score. Note that the decision tree depth is fixed in my own function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of f1 scores using a list comprehension\n",
    "\n",
    "featurelist = [2,5,10,50,100,500]\n",
    "depth = 2\n",
    "f1list = [f1score(i,depth) for i in featurelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to plot this, we use matplotlib which you should have installed if you are using the anaconda distribution. \n",
    "# If you’re using the code in the walkthrough, matplotlib is part of the import statements.  \n",
    "# You should add another line, %pylab inline , and the import statement,  import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(featurelist,f1list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One final thing to do: do a similar plot for the accuracy metric. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
